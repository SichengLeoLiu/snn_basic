{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "658ee506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from typing import Iterable\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data import get_mnist_dataloaders, get_cifar10_dataloaders\n",
    "from snn import SNNMLP, SNNResNet18, poisson_encode, static_encode\n",
    "\n",
    "\n",
    "def accuracy(logits: torch.Tensor, targets: torch.Tensor) -> float:\n",
    "\tpred = logits.argmax(dim=1)\n",
    "\treturn (pred == targets).float().mean().item()\n",
    "\n",
    "\n",
    "def run_epoch(\n",
    "\tmodel: nn.Module,\n",
    "\tloader,\n",
    "\tdevice: torch.device,\n",
    "\toptimizer: torch.optim.Optimizer | None,\n",
    "\tsteps: int,\n",
    "\ttrain: bool,\n",
    "\tprogress_desc: str,\n",
    ") -> tuple[float, float]:\n",
    "\tif train:\n",
    "\t\tmodel.train(mode=train)\n",
    "\telse:\n",
    "\t\tmodel.eval()\n",
    "\tcriterion = nn.CrossEntropyLoss()\n",
    "\ttotal_loss = 0.0\n",
    "\ttotal_acc = 0.0\n",
    "\tcount = 0\n",
    "\tfor images, labels in tqdm(loader, desc=progress_desc, leave=False):\n",
    "\t\timages = images.to(device)\n",
    "\t\tlabels = labels.to(device)\n",
    "\t\tif train:\n",
    "\t\t\toptimizer.zero_grad(set_to_none=True)\n",
    "\t\t# 泊松编码时间序列 → 模型 → 平均 logits\n",
    "\t\tspike_seq = static_encode(images, steps)\n",
    "\t\tT = len(spike_seq)\n",
    "\n",
    "\t\t# 生成时间维度的随机排列索引\n",
    "\t\tperm = torch.randperm(T)\n",
    "\n",
    "\t\t# 根据该随机排列重新索引时间维度\n",
    "\t\tspike_seq = spike_seq[perm, :, :]\n",
    "\t\tlogits = model.forward_sequence(spike_seq)\n",
    "\t\tloss = criterion(logits, labels)\n",
    "\t\tif train:\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\tacc = accuracy(logits.detach(), labels)\n",
    "\t\tbatch = images.size(0)\n",
    "\t\ttotal_loss += loss.detach().item() * batch\n",
    "\t\ttotal_acc += acc * batch\n",
    "\t\tcount += batch\n",
    "\treturn total_loss / count, total_acc / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703d949b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 79 (1697412634.py, line 80)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[11], line 80\u001b[1;36m\u001b[0m\n\u001b[1;33m    \"\"\"步骤1：Conv Block 1 + Pool1\"\"\"\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after function definition on line 79\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from typing import Iterable\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from snn.neurons import LIFNeuron, SpikeConv2d, SpikeOutputLayer\n",
    "\n",
    "\n",
    "class SNNVGG9(nn.Module):\n",
    "\t\"\"\"VGG9的SNN版本\n",
    "\t\n",
    "\tVGG9是一个简化的VGG网络，包含9个卷积层。\n",
    "\t适用于CIFAR-10等小尺寸图像数据集。\n",
    "\t对于MNIST等1通道图像，需要调整输入通道数。\n",
    "\t\n",
    "\t结构：\n",
    "\t- Conv Block 1: 64 channels, 2 layers\n",
    "\t- Conv Block 2: 128 channels, 2 layers  \n",
    "\t- Conv Block 3: 256 channels, 2 layers\n",
    "\t- Global Average Pooling\n",
    "\t- Output Layer\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tdef __init__(\n",
    "\t\tself,\n",
    "\t\tnum_classes: int = 10,\n",
    "\t\tin_channels: int = 3,\n",
    "\t\tnorm_layer: type[nn.Module] | None = None,\n",
    "\t):\n",
    "\t\tsuper().__init__()\n",
    "\t\tif norm_layer is None:\n",
    "\t\t\tnorm_layer = nn.BatchNorm2d\n",
    "\t\t\n",
    "\t\t# Conv Block 1: 64 channels\n",
    "\t\tself.conv_block1 = nn.Sequential(\n",
    "\t\t\tSpikeConv2d(in_channels, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "\t\t\tnorm_layer(64),\n",
    "\t\t\tLIFNeuron(),\n",
    "\t\t\tSpikeConv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "\t\t\tnorm_layer(64),\n",
    "\t\t\tLIFNeuron(),\n",
    "\t\t)\n",
    "\t\tself.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\t\t\n",
    "\t\t# Conv Block 2: 128 channels\n",
    "\t\tself.conv_block2 = nn.Sequential(\n",
    "\t\t\tSpikeConv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "\t\t\tnorm_layer(128),\n",
    "\t\t\tLIFNeuron(),\n",
    "\t\t\tSpikeConv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "\t\t\tnorm_layer(128),\n",
    "\t\t\tLIFNeuron(),\n",
    "\t\t)\n",
    "\t\tself.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\t\t\n",
    "\t\t# Conv Block 3: 256 channels\n",
    "\t\tself.conv_block3 = nn.Sequential(\n",
    "\t\t\tSpikeConv2d(128, 256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "\t\t\tnorm_layer(256),\n",
    "\t\t\tLIFNeuron(),\n",
    "\t\t\tSpikeConv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "\t\t\tnorm_layer(256),\n",
    "\t\t\tLIFNeuron(),\n",
    "\t\t)\n",
    "\t\tself.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\t\t\n",
    "\t\t# 全局平均池化和输出层\n",
    "\t\tself.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\t\tself.fc = SpikeOutputLayer(256, num_classes)\n",
    "\t\n",
    "\tdef reset_state(self) -> None:\n",
    "\t\t\"\"\"重置所有LIF神经元和输出层的状态\"\"\"\n",
    "\t\tfor module in self.modules():\n",
    "\t\t\tif isinstance(module, (LIFNeuron, SpikeOutputLayer)):\n",
    "\t\t\t\tmodule.reset_state()\n",
    "\t\n",
    " \n",
    " \tdef forward_step1(self, x_t: torch.Tensor) -> torch.Tensor:\n",
    "\t\t\"\"\"步骤1：Conv Block 1 + Pool1\"\"\"\n",
    "\t\tx = self.conv_block1(x_t)\n",
    "\t\tx = self.pool1(x)\n",
    "\t\treturn x\n",
    "\n",
    "\tdef forward_step2(self, x_t: torch.Tensor) -> torch.Tensor:\n",
    "\t\t\"\"\"步骤2：Conv Block 2 + Pool2\"\"\"\n",
    "\t\tx = self.conv_block2(x_t)\n",
    "\t\tx = self.pool2(x)\n",
    "\t\treturn x\n",
    "\n",
    "\tdef forward_step3(self, x_t: torch.Tensor) -> torch.Tensor:\n",
    "\t\t\"\"\"步骤3：Conv Block 3 + Pool3\"\"\"\n",
    "\t\tx = self.conv_block3(x_t)\n",
    "\t\tx = self.pool3(x)\n",
    "\t\treturn x\n",
    "\n",
    "\tdef forward_step4(self, x_t: torch.Tensor) -> torch.Tensor:\n",
    "\t\t\"\"\"步骤4：全局平均池化 + Flatten\"\"\"\n",
    "\t\tx = self.avgpool(x_t)\n",
    "\t\tx = x.flatten(1)  # [B, 256]\n",
    "\t\treturn x\n",
    "\n",
    "\tdef forward_step5(self, x_t: torch.Tensor) -> torch.Tensor:\n",
    "\t\t\"\"\"步骤5：输出层（累积输出）\"\"\"\n",
    "\t\tlogits = self.fc(x_t)\n",
    "\t\treturn logits\n",
    "\n",
    "\tdef forward_step(self, x_t: torch.Tensor) -> torch.Tensor:\n",
    "\t\t\"\"\"完整的单时间步前向传播（保持向后兼容）\"\"\"\n",
    "\t\tx = self.forward_step1(x_t)\n",
    "\t\tx = self.forward_step2(x)\n",
    "\t\tx = self.forward_step3(x)\n",
    "\t\tx = self.forward_step4(x)\n",
    "\t\tlogits = self.forward_step5(x)\n",
    "\t\treturn logits\n",
    "\n",
    "\tdef forward_sequence(\n",
    "\t\tself, \n",
    "\t\tspike_sequence: Iterable[torch.Tensor] | torch.Tensor,\n",
    "\t\tshuffle_after_steps: list[int] | None = None\n",
    "\t) -> torch.Tensor:\n",
    "\t\t\"\"\"处理时间序列的脉冲输入，支持在指定步骤后打乱时间步\n",
    "\t\t\n",
    "\t\tArgs:\n",
    "\t\t\tspike_sequence: 时间序列的脉冲输入（tensor [T, B, ...] 或生成器）\n",
    "\t\t\tshuffle_after_steps: 在哪些步骤后打乱时间步，例如 [1, 2] 表示在步骤1和2后打乱\n",
    "\t\t\t\t\t\t\t\t步骤编号：\n",
    "\t\t\t\t\t\t\t\t1: forward_step1 后（conv_block1 + pool1）\n",
    "\t\t\t\t\t\t\t\t2: forward_step2 后（conv_block2 + pool2）\n",
    "\t\t\t\t\t\t\t\t3: forward_step3 后（conv_block3 + pool3）\n",
    "\t\t\t\t\t\t\t\t4: forward_step4 后（avgpool + flatten）\n",
    "\t\t\n",
    "\t\tReturns:\n",
    "\t\t\tlogits: [B, num_classes]\n",
    "\t\t\"\"\"\n",
    "\t\tself.reset_state()\n",
    "\t\t\n",
    "\t\t# 先收集所有时间步\n",
    "\t\tif isinstance(spike_sequence, torch.Tensor):\n",
    "\t\t\t# 如果是tensor [T, B, C, H, W]\n",
    "\t\t\tspike_list = [spike_sequence[i] for i in range(spike_sequence.shape[0])]\n",
    "\t\telse:\n",
    "\t\t\t# 如果是生成器，转换为列表\n",
    "\t\t\tspike_list = list(spike_sequence)\n",
    "\t\t\n",
    "\t\tT = len(spike_list)\n",
    "\t\tif shuffle_after_steps is None:\n",
    "\t\t\tshuffle_after_steps = []\n",
    "\t\t\n",
    "\t\t# 步骤1：Conv Block 1 + Pool1\n",
    "\t\t# 对所有时间步执行步骤1\n",
    "\t\tx_sequence = [self.forward_step1(x_t) for x_t in spike_list]\n",
    "\t\t\n",
    "\t\t# 在步骤1后打乱（如果需要）\n",
    "\t\tif 1 in shuffle_after_steps:\n",
    "\t\t\tx_tensor = torch.stack(x_sequence, dim=0)  # [T, B, C, H, W]\n",
    "\t\t\tperm = torch.randperm(T, device=x_tensor.device)\n",
    "\t\t\tx_tensor = x_tensor[perm]\n",
    "\t\t\tx_sequence = [x_tensor[i] for i in range(T)]\n",
    "\t\t\t# 重置步骤1之后所有层的状态\n",
    "\t\t\tfor module in self.conv_block2.modules():\n",
    "\t\t\t\tif isinstance(module, LIFNeuron):\n",
    "\t\t\t\t\tmodule.reset_state()\n",
    "\t\t\tfor module in self.conv_block3.modules():\n",
    "\t\t\t\tif isinstance(module, LIFNeuron):\n",
    "\t\t\t\t\tmodule.reset_state()\n",
    "\t\t\tself.fc.reset_state()\n",
    "\t\t\n",
    "\t\t# 步骤2：Conv Block 2 + Pool2\n",
    "\t\tx_sequence = [self.forward_step2(x_t) for x_t in x_sequence]\n",
    "\t\t\n",
    "\t\t# 在步骤2后打乱（如果需要）\n",
    "\t\tif 2 in shuffle_after_steps:\n",
    "\t\t\tx_tensor = torch.stack(x_sequence, dim=0)\n",
    "\t\t\tperm = torch.randperm(T, device=x_tensor.device)\n",
    "\t\t\tx_tensor = x_tensor[perm]\n",
    "\t\t\tx_sequence = [x_tensor[i] for i in range(T)]\n",
    "\t\t\t# 重置步骤2之后所有层的状态\n",
    "\t\t\tfor module in self.conv_block3.modules():\n",
    "\t\t\t\tif isinstance(module, LIFNeuron):\n",
    "\t\t\t\t\tmodule.reset_state()\n",
    "\t\t\tself.fc.reset_state()\n",
    "\t\t\n",
    "\t\t# 步骤3：Conv Block 3 + Pool3\n",
    "\t\tx_sequence = [self.forward_step3(x_t) for x_t in x_sequence]\n",
    "\t\t\n",
    "\t\t# 在步骤3后打乱（如果需要）\n",
    "\t\tif 3 in shuffle_after_steps:\n",
    "\t\t\tx_tensor = torch.stack(x_sequence, dim=0)\n",
    "\t\t\tperm = torch.randperm(T, device=x_tensor.device)\n",
    "\t\t\tx_tensor = x_tensor[perm]\n",
    "\t\t\tx_sequence = [x_tensor[i] for i in range(T)]\n",
    "\t\t\t# 重置步骤3之后所有层的状态\n",
    "\t\t\tself.fc.reset_state()\n",
    "\t\t\n",
    "\t\t# 步骤4：全局平均池化 + Flatten\n",
    "\t\tx_sequence = [self.forward_step4(x_t) for x_t in x_sequence]\n",
    "\t\t\n",
    "\t\t# 在步骤4后打乱（如果需要）\n",
    "\t\tif 4 in shuffle_after_steps:\n",
    "\t\t\tx_tensor = torch.stack(x_sequence, dim=0)  # [T, B, 256]\n",
    "\t\t\tperm = torch.randperm(T, device=x_tensor.device)\n",
    "\t\t\tx_tensor = x_tensor[perm]\n",
    "\t\t\tx_sequence = [x_tensor[i] for i in range(T)]\n",
    "\t\t\tself.fc.reset_state()\n",
    "\t\t\n",
    "\t\t# 步骤5：输出层（累积所有时间步）\n",
    "\t\tfor x_t in x_sequence:\n",
    "\t\t\tlogits_t = self.forward_step5(x_t)\n",
    "\t\t\n",
    "\t\t# SpikeOutputLayer 已经累积了所有时间步的输出\n",
    "\t\treturn logits_t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7433cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.9841, Test accuracy: 0.7608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.random.manual_seed(42)\n",
    "# 配置参数\n",
    "ckpt_path = \"checkpoints/best_snn_vgg9_cifar10.pt\"  # 修改为你的模型和数据集类型保存的模型路径\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 64\n",
    "steps = 20\n",
    "\n",
    "# 数据加载\n",
    "_, test_loader = get_cifar10_dataloaders(batch_size=batch_size)\n",
    "\n",
    "# 加载模型\n",
    "model = SNNVGG9(num_classes=10, in_channels=3)\n",
    "model.to(device)\n",
    "\n",
    "# 加载权重\n",
    "ckpt = torch.load(ckpt_path, map_location=device)\n",
    "model.load_state_dict(ckpt['model_state'])\n",
    "model.eval()\n",
    "\n",
    "# 测试\n",
    "test_loss, test_acc = run_epoch(model, test_loader, device, optimizer=None, steps=steps, train=False, progress_desc=\"Test\")\n",
    "print(f\"Test loss: {test_loss:.4f}, Test accuracy: {test_acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc00b85d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
